{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5e231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-01 13:47:05,577] INFO: base_url: https://openrouter.ai/api/v1, api_key: sk-or-v1-87d...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_url: https://openrouter.ai/api/v1, api_key: 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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-01 13:47:05,948] INFO: [skip] anthropic-claude-3.7-sonnet step 0: missing one of global/local/prompt/output\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "score_model.py — step-level scorer (OpenRouter, no CLI flags)\n",
    "\n",
    "- 扫描 ROOT_DIR 中 {model}_{step}_{kind}.{ext} 命名的文件：\n",
    "  kinds ∈ {global.png, local.png, prompt.txt, output.txt}（忽略 fpv）\n",
    "- 解析 output.txt（从混合文本里抽取 JSON；不合法则跳过该 step）\n",
    "- 调用 OpenRouter 上的 gpt-4o 按 6 个维度打分（0–10；未体现为 -1；collaboration 强制 -1）\n",
    "- 输出到 OUT_DIR/{model}_scores.jsonl（每行一个 step 的记录）\n",
    "- 任何解析失败会把原始 LLM 响应落盘 OUT_DIR/_raw/ 便于排查\n",
    "\n",
    "依赖：\n",
    "  - llm/score_model.py 里的 BaseModel（HTTP/重试/超时等）\n",
    "  - pip: pillow numpy openai\n",
    "环境变量：\n",
    "  - OPENROUTER_KEY（推荐）\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, json, uuid, logging\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# === 路径：按你的工程实际调整 ===\n",
    "SIMWORLD_DIR      = r\"D:\\BaiduNetdiskDownload\\Food-Delivery-Bench-2.0-iso\\SimWorld\"\n",
    "LLM_DELIVERY_DIR  = r\"D:\\BaiduNetdiskDownload\\Food-Delivery-Bench-2.0-iso\\LLM-Delivery\"\n",
    "sys.path.insert(0, SIMWORLD_DIR); sys.path.insert(0, LLM_DELIVERY_DIR)\n",
    "from llm.score_model import BaseModel  # 复用你已有的 BaseModel（负责 HTTP/重试/超时等）\n",
    "\n",
    "# =========================\n",
    "# CONFIG（集中修改）\n",
    "# =========================\n",
    "ROOT_DIR = r\"D:\\BaiduNetdiskDownload\\Food-Delivery-Bench-2.0-iso\\LLM-Delivery\\Scripts\\debug_snaps\\medium-20\"\n",
    "OUT_DIR  = r\"D:\\BaiduNetdiskDownload\\Food-Delivery-Bench-2.0-iso\\LLM-Delivery\\Scripts\\debug_snaps\\medium-20-scores\"\n",
    "\n",
    "# OpenRouter 设置（OpenAI SDK 兼容）\n",
    "BASE_URL = \"https://openrouter.ai/api/v1\"  # ✅ 更稳的子域\n",
    "API_KEY  = os.getenv(\"OPENROUTER_KEY\", \"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\")\n",
    "SCORER_MODEL = \"openai/gpt-4o\"     # 可改 openai/gpt-4o-mini 等\n",
    "RATE_LIMIT_PER_MIN = 30            # 简单的 QPS 节流\n",
    "\n",
    "# 文件名解析\n",
    "FNAME_RE = re.compile(\n",
    "    r\"^(?P<model>.+?)_(?P<step>\\d+)_(?P<kind>fpv|global|local|prompt|output)\\.(?P<ext>png|txt)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 工具函数：宽松 JSON 提取/清洗\n",
    "# =========================\n",
    "def _strip_code_fences(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"^\\s*```(?:json)?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s*```\\s*$\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _extract_json_loose(s: str) -> dict:\n",
    "    \"\"\"\n",
    "    从任意 LLM 文本里尽力抽取一个 JSON 对象：\n",
    "    - 去掉 ```json/``` 包裹\n",
    "    - 先尝试整体 loads；失败再截取最外层 { ... } 子串；再失败枚举起始花括号\n",
    "    - 失败则抛出 ValueError\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        raise ValueError(\"LLM response is not a string\")\n",
    "\n",
    "    s = _strip_code_fences(s)\n",
    "\n",
    "    # 快速路径：直接尝试 loads\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 宽松路径：找第一个 '{' 到最后一个 '}' 的子串再 loads\n",
    "    try:\n",
    "        i = s.index(\"{\")\n",
    "        j = s.rindex(\"}\") + 1\n",
    "        obj = json.loads(s[i:j])\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 再宽松：找所有可能的 { ... } 片段，逐个尝试\n",
    "    braces = [m.start() for m in re.finditer(r\"\\{\", s)]\n",
    "    for i in braces:\n",
    "        try:\n",
    "            sub = s[i:s.rindex(\"}\")+1]\n",
    "            obj = json.loads(sub)\n",
    "            if isinstance(obj, dict):\n",
    "                return obj\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # 全部失败\n",
    "    raise ValueError(\"Cannot extract valid JSON from LLM response\")\n",
    "\n",
    "# =========================\n",
    "# 提示词\n",
    "# =========================\n",
    "def build_system_prompt() -> str:\n",
    "    \"\"\"\n",
    "    概念优先 + 非穷举示例 + 自主补充信号 + 反事实比较 + 以遗漏为主的理由\n",
    "    严格 JSON 输出（不给 markdown/code fences）\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"You are a meticulous step-level evaluator for a SINGLE-AGENT delivery task.\\n\"\n",
    "        \"You will receive for THIS step: (1) GLOBAL MAP image, (2) LOCAL MAP image, and \"\n",
    "        \"(3) TEXT containing the agent's prompt (state/rules/history) plus the agent's JSON output for THIS step.\\n\\n\"\n",
    "\n",
    "        \"GENERAL PRINCIPLES (read carefully):\\n\"\n",
    "        \"- Each dimension is a CONCEPT (e.g., risk = aggressiveness vs conservatism). The examples below are NON-EXHAUSTIVE.\\n\"\n",
    "        \"- First understand the concept definition, then look for ANY reasonable signals in THIS step that align with the concept—not only the examples listed.\\n\"\n",
    "        \"- If THIS step provides no clear evidence for a dimension, return -1 for that dimension (do NOT guess).\\n\"\n",
    "        \"- Reasons must be SHORT (1–2 concise clauses), SPECIFIC, and should emphasize OMISSIONS/RISKS as much as positives.\\n\"\n",
    "        \"- Always apply a light COUNTERFACTUAL check: what would a more aggressive/cautious, longer-term, more diverse, more meticulous, or more adaptive plan look like in THIS state?\\n\"\n",
    "        \"- Use the full 0–10 range (integers). Avoid only {0,5,10}. Penalize shallow planning and missing safety/constraint handling.\\n\"\n",
    "        \"- Do not hedge to the mid-range: if THIS step is clearly exemplary on a dimension with specific, step-grounded evidence, assign 9–10; if it clearly neglects or endangers the dimension, assign 0–2.\\n\"\n",
    "        \"- Use -1 only when there is truly no evidence in THIS step.\\n\"\n",
    "        \"- STRICT JSON ONLY in your final output (no markdown, no code fences, no extra prose).\\n\\n\"\n",
    "\n",
    "        \"SCORING RUBRIC (concept → anchors → typical/non-exhaustive signals; consider ANY consistent signals in THIS step):\\n\"\n",
    "\n",
    "        \"1) risk (aggressiveness vs conservatism):\\n\"\n",
    "        \"   Concept: how bold vs cautious the decision is, given time windows, geography, agent energy/scooter battery, and payoff tradeoffs.\\n\"\n",
    "        \"   Anchors: 0=extremely cautious; 3=cautious; 5=balanced; 7=aggressive; 10=extremely aggressive.\\n\"\n",
    "        \"   Aggressive (high) signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Accepts many orders at once, especially with tight/conflicting ETAs.\\n\"\n",
    "        \"     • Prefers far/high-payout routes even if sequencing/charging is risky.\\n\"\n",
    "        \"     • Proceeds while energy/battery is low, betting it will suffice; skips mitigations (e.g., charging) to save time.\\n\"\n",
    "        \"   Conservative (low) signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Takes one safe order at a time; proactively charges/rests before urgent.\\n\"\n",
    "        \"   Counterfactual prompt: What clearly safer/bolder option was available right now?\\n\\n\"\n",
    "\n",
    "        \"2) long_term (foresight & chaining):\\n\"\n",
    "        \"   Concept: multi-step foresight, temporal/geographic chaining, and strategic investments shown in THIS step.\\n\"\n",
    "        \"   Anchors: 0=myopic; 3=weak foresight; 5=moderate; 7=strong; 10=exceptional.\\n\"\n",
    "        \"   Positive signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Sequences pickups/dropoffs by proximity and time windows to minimize detours.\\n\"\n",
    "        \"     • Buys/uses tools (energy drink, battery pack) as strategic investment; schedules a short charge near future POIs.\\n\"\n",
    "        \"     • Avoids routes/areas that will complicate later charging or sequencing.\\n\"\n",
    "        \"   Anti-signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Selects orders without considering next-stop geography or charger availability; only maximizes immediate payout.\\n\"\n",
    "        \"   Counterfactual prompt: What chaining or investment now would reduce future risk/cost/delay?\\n\\n\"\n",
    "\n",
    "        \"3) diversity (strategy variety beyond routine):\\n\"\n",
    "        \"   Concept: use of non-routine tools/transports/mechanisms beyond the standard charge→accept→pickup→deliver loop.\\n\"\n",
    "        \"   Anchors: 0=routine only; 3=minor variation; 5=some variety; 7=clear variety; 10=rich toolkit.\\n\"\n",
    "        \"   Signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Takes a bus; rents/returns a car; visits store to buy/USE tools (ice/heat packs, battery pack, energy drink).\\n\"\n",
    "        \"     • Purposeful detours that unlock speed/reliability later (e.g., staging, temp storage allowed by rules, etc.).\\n\"\n",
    "        \"   Counterfactual prompt: Which extra mechanism would reduce time/risk/cost now?\\n\\n\"\n",
    "\n",
    "        \"4) collaboration:\\n\"\n",
    "        \"   ALWAYS -1 in this single-agent setting (explain as such). Ignore incidental mentions.\\n\\n\"\n",
    "\n",
    "        \"5) meticulousness (operational detail & constraints):\\n\"\n",
    "        \"   Concept: care for perishables/temperature, drop-off method, fragility, movement side-effects, and special instructions.\\n\"\n",
    "        \"   Anchors: 0=careless; 3=partial; 5=several but with gaps; 7=thorough; 10=exemplary.\\n\"\n",
    "        \"   Checks when relevant (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Ice-cream melting urgency handled; hot/cold separation; pungent items not mixed with drinks/desserts.\\n\"\n",
    "        \"     • Fragile items avoid aggressive movement; respects specified drop-off method (e.g., hand_to_customer with egocentric search).\\n\"\n",
    "        \"     • Honors time windows and customer instructions; anticipates temperature packs.\\n\"\n",
    "        \"   Counterfactual prompt: Which concrete mitigation (separation, pack, speed choice) was missed right now?\\n\\n\"\n",
    "\n",
    "        \"6) adaptability (updates plan given new state/errors):\\n\"\n",
    "        \"   Concept: responsiveness to updated info (energy/battery/time windows/recent_error), re-ordering or switching resources.\\n\"\n",
    "        \"   Anchors: 0=rigid; 3=slight; 5=reasonable for one issue; 7=solid; 10=excellent across multiple issues.\\n\"\n",
    "        \"   Signals (NON-EXHAUSTIVE):\\n\"\n",
    "        \"     • Deviates from prior plan after noticing conflicts; charge-first on low battery; re-sequences deliveries; switches transport.\\n\"\n",
    "        \"   Counterfactual prompt: Which change (charge first, reorder, different transport) would better fit the new state?\\n\\n\"\n",
    "\n",
    "        \"EXEMPLAR ILLUSTRATION (do NOT copy; evaluate THIS step only):\\n\"\n",
    "        \"  scores.risk = 8 because the agent accepted three tight-window orders and kept going despite low energy/battery; a safer plan would drop one order or charge first.\\n\"\n",
    "        \"  scores.long_term = 3 because the delivery sequence ignored spatial chaining and charger scarcity near #4; a better plan would deliver #6 first or pre-charge nearby.\\n\"\n",
    "        \"  scores.diversity = 2 because it mainly followed the routine; taking a bus or buying a battery pack would diversify strategy.\\n\"\n",
    "        \"  scores.collaboration = -1 (single-agent setup).\\n\"\n",
    "        \"  scores.meticulousness = 6 because it noticed ice-cream melting and special instructions, but mixed a pungent item with a drink; separation/pack usage was only partial.\\n\"\n",
    "        \"  scores.adaptability = 6 because it adjusted after noticing low battery (some plan change), though not fully optimized.\\n\\n\"\n",
    "\n",
    "        # === 插入的严格对齐示例（格式演示；内容不得照搬） ===\n",
    "        \"EXAMPLE_OUTPUT (FORMAT-ALIGNED; CONTENT IS ILLUSTRATIVE AND MUST NOT BE COPIED VERBATIM):\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"scores\\\": {\\n\"\n",
    "        \"    \\\"risk\\\": 8,\\n\"\n",
    "        \"    \\\"long_term\\\": 3,\\n\"\n",
    "        \"    \\\"diversity\\\": 2,\\n\"\n",
    "        \"    \\\"collaboration\\\": -1,\\n\"\n",
    "        \"    \\\"meticulousness\\\": 6,\\n\"\n",
    "        \"    \\\"adaptability\\\": 6\\n\"\n",
    "        \"  },\\n\"\n",
    "        \"  \\\"reasons\\\": {\\n\"\n",
    "        \"    \\\"risk\\\": \\\"Accepted three tight-window orders and continued despite low energy/battery; map distances imply limited buffer—safer plan was dropping one or charging first for reliability.\\\",\\n\"\n",
    "        \"    \\\"long_term\\\": \\\"Sequence ignored spatial chaining and charger scarcity near #4; delivering #6 earlier or pre-charging en route would reduce later detours and timing risk.\\\",\\n\"\n",
    "        \"    \\\"diversity\\\": \\\"Mostly routine pipeline (accept→pickup→deliver); no deliberate tool choice like battery pack/ice/heat or purposeful transport switch beyond a one-off bus ride.\\\",\\n\"\n",
    "        \"    \\\"collaboration\\\": \\\"Single-agent setup; collaboration not applicable.\\\",\\n\"\n",
    "        \"    \\\"meticulousness\\\": \\\"Acknowledged ice-cream melting and special instructions but co-located a pungent item with a drink and did not mention packs/separation explicitly—partial care with gaps.\\\",\\n\"\n",
    "        \"    \\\"adaptability\\\": \\\"Departed from earlier plan after noticing low battery (some resequencing), yet did not fully re-optimize around nearby chargers or tighter windows—moderate adaptation.\\\"\\n\"\n",
    "        \"  }\\n\"\n",
    "        \"}\\n\\n\"\n",
    "\n",
    "        \"EVIDENCE & REASONS:\\n\"\n",
    "        \"- Ground each reason in THIS step’s specifics (accepted orders, map-implied distances, time windows, energy/battery %, drop-off method, melting/fragile risks, recent_error, post_action_plan vs current action).\\n\"\n",
    "        \"- Prefer omission-focused critique: what was missed (e.g., pre-charge near #4; separation of pungent items; honoring hand_to_customer search).\\n\\n\"\n",
    "\n",
    "        \"OUTPUT FORMAT — STRICT JSON ONLY (no markdown, no code fences):\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \\\"scores\\\": {\\n'\n",
    "        '    \\\"risk\\\": int, \\\"long_term\\\": int, \\\"diversity\\\": int, \\\"collaboration\\\": int, \\\"meticulousness\\\": int, \\\"adaptability\\\": int\\n'\n",
    "        \"  },\\n\"\n",
    "        '  \\\"reasons\\\": {\\n'\n",
    "        '    \\\"risk\\\": \\\"short omission-focused reason grounded in THIS step\\\",\\n'\n",
    "        '    \\\"long_term\\\": \\\"short omission-focused reason grounded in THIS step\\\",\\n'\n",
    "        '    \\\"diversity\\\": \\\"short omission-focused reason grounded in THIS step\\\",\\n'\n",
    "        '    \\\"collaboration\\\": \\\"single-agent setting; not applicable\\\",\\n'\n",
    "        '    \\\"meticulousness\\\": \\\"short omission-focused reason grounded in THIS step\\\",\\n'\n",
    "        '    \\\"adaptability\\\": \\\"short omission-focused reason grounded in THIS step\\\"\\n'\n",
    "        \"  }\\n\"\n",
    "        \"}\\n\"\n",
    "    )\n",
    "\n",
    "def build_user_block(prompt_text: str, output_json_str: str) -> str:\n",
    "    \"\"\"\n",
    "    合并 prompt 与该 step 的 output JSON。\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"### PROMPT (observation/rules/context)\\n\" + prompt_text.strip() + \"\\n\\n\" +\n",
    "        \"### MODEL_OUTPUT_JSON (for THIS step)\\n\" + output_json_str.strip() + \"\\n\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# I/O\n",
    "# =========================\n",
    "def open_image(path: str) -> Image.Image:\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def load_text(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def group_files(root: str) -> Dict[Tuple[str, int], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    返回 (model, step) -> {kind: filepath}\n",
    "    需要 kinds: global, local, prompt, output   （fpv 忽略）\n",
    "    \"\"\"\n",
    "    groups: Dict[Tuple[str, int], Dict[str, str]] = {}\n",
    "    for name in os.listdir(root):\n",
    "        m = FNAME_RE.match(name)\n",
    "        if not m:\n",
    "            continue\n",
    "        model = m.group(\"model\")\n",
    "        step = int(m.group(\"step\"))\n",
    "        kind = m.group(\"kind\").lower()\n",
    "        path = os.path.join(root, name)\n",
    "        key = (model, step)\n",
    "        groups.setdefault(key, {})\n",
    "        groups[key][kind] = path\n",
    "    return groups\n",
    "\n",
    "def parse_output_json(text: str) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    从 output.txt 中定位并解析 JSON；失败返回 None。\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        i = text.index(\"{\")\n",
    "        j = text.rindex(\"}\") + 1\n",
    "        obj = json.loads(text[i:j])\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# 核心：打分（带宽松解析与落盘）\n",
    "# =========================\n",
    "def score_one_step(\n",
    "    scorer: BaseModel,\n",
    "    system_prompt: str,\n",
    "    global_img_path: str,\n",
    "    local_img_path: str,\n",
    "    prompt_text: str,\n",
    "    output_json_text: str,\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    评分一个 step；返回 {\"scores\": {...}, \"reasons\": {...}} 或 None。\n",
    "    \"\"\"\n",
    "    images = [open_image(global_img_path), open_image(local_img_path)]\n",
    "    user_text = build_user_block(prompt_text, output_json_text)\n",
    "\n",
    "    resp = scorer.generate(\n",
    "        system=system_prompt,\n",
    "        user=user_text,\n",
    "        images=images,\n",
    "        max_tokens=350,\n",
    "        temperature=0.0,\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    # 失败时把原始响应落盘，便于审计\n",
    "    def dump_raw(reason: str):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(OUT_DIR, \"_raw\"), exist_ok=True)\n",
    "            fname = os.path.join(OUT_DIR, \"_raw\", f\"resp_{uuid.uuid4().hex[:8]}_{reason}.txt\")\n",
    "            with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(resp if isinstance(resp, str) else repr(resp))\n",
    "            logging.error(f\"[debug] dumped raw LLM response to: {fname}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        data = _extract_json_loose(resp)  # ← 宽松解析\n",
    "\n",
    "        # 结构容错：允许只有 scores，没有 reasons；或 key 大小写/别名错误\n",
    "        scores = data.get(\"scores\") or data.get(\"Scores\") or {}\n",
    "        reasons = data.get(\"reasons\") or data.get(\"Reasons\") or {}\n",
    "\n",
    "        # 若模型直接平铺在顶层（没有 scores/reasons），也容错接住（但仍以 want_keys 过滤）\n",
    "        if not isinstance(scores, dict):\n",
    "            scores = {k: v for k, v in data.items() if isinstance(v, (int, float, str))}\n",
    "            reasons = data.get(\"reasons\", {}) if isinstance(data.get(\"reasons\"), dict) else reasons\n",
    "\n",
    "        # 协作维度固定为 -1（双保险）\n",
    "        if not isinstance(scores, dict):\n",
    "            scores = {}\n",
    "        if not isinstance(reasons, dict):\n",
    "            reasons = {}\n",
    "        scores[\"collaboration\"] = -1\n",
    "        reasons[\"collaboration\"] = reasons.get(\n",
    "            \"collaboration\",\n",
    "            \"Single-agent setting: collaboration not applicable.\"\n",
    "        )\n",
    "\n",
    "        want_keys = [\"risk\", \"long_term\", \"diversity\", \"collaboration\", \"meticulousness\", \"adaptability\"]\n",
    "        clean_scores: Dict[str, int] = {}\n",
    "        clean_reasons: Dict[str, str] = {}\n",
    "\n",
    "        for k in want_keys:\n",
    "            raw_v = scores.get(k, -1)\n",
    "            try:\n",
    "                v = int(raw_v)\n",
    "            except Exception:\n",
    "                # 兜 \"7/10\"、\"8.\" 之类\n",
    "                try:\n",
    "                    v = int(float(str(raw_v).replace(\"/10\", \"\").strip()))\n",
    "                except Exception:\n",
    "                    v = -1\n",
    "            v = max(-1, min(10, v))\n",
    "            clean_scores[k] = v\n",
    "\n",
    "            r = reasons.get(k, \"\")\n",
    "            if not isinstance(r, str) or not r.strip():\n",
    "                r = \"No specific evidence found in this step.\" if v == -1 else \"Reason not provided.\"\n",
    "            r = _strip_code_fences(r).replace(\"\\n\", \" \").strip()\n",
    "            clean_reasons[k] = r\n",
    "\n",
    "        return {\"scores\": clean_scores, \"reasons\": clean_reasons}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Scorer response not parseable: {e}\")\n",
    "        dump_raw(\"parse_fail\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# 主流程\n",
    "# =========================\n",
    "def main():\n",
    "    if not API_KEY:\n",
    "        raise RuntimeError(\"OPENROUTER_KEY not found. Please set it in your environment.\")\n",
    "\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(levelname)s: %(message)s\")\n",
    "    logging.info(f\"base_url: {BASE_URL}, api_key: {API_KEY[:12]}...\")\n",
    "\n",
    "    # 构造 LLM 评分器（走 OpenRouter）\n",
    "    scorer = BaseModel(\n",
    "        url=BASE_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=SCORER_MODEL,\n",
    "        max_tokens=256,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        rate_limit_per_min=RATE_LIMIT_PER_MIN,\n",
    "        supports_vision=True,\n",
    "        # 如果你的 BaseModel 支持超时/headers，这里也可以加（否则忽略）：\n",
    "        # http_timeout_s=60.0, referer=\"https://your.site\", app_title=\"DeliveryBench-Scorer\",\n",
    "    )\n",
    "    system_prompt = build_system_prompt()\n",
    "\n",
    "    groups = group_files(ROOT_DIR)\n",
    "    per_model: Dict[str, List[Tuple[int, Dict[str, str]]]] = {}\n",
    "    for (model, step), files in groups.items():\n",
    "        per_model.setdefault(model, []).append((step, files))\n",
    "\n",
    "    for model, items in per_model.items():\n",
    "        items.sort(key=lambda x: x[0])\n",
    "        out_path = os.path.join(OUT_DIR, f\"{model}_scores.jsonl\")\n",
    "        written = 0\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "            for step, files in items:\n",
    "                # 需要四件：global/local/prompt/output\n",
    "                if not all(k in files for k in (\"global\", \"local\", \"prompt\", \"output\")):\n",
    "                    logging.info(f\"[skip] {model} step {step}: missing one of global/local/prompt/output\")\n",
    "                    continue\n",
    "\n",
    "                prompt_text = load_text(files[\"prompt\"])\n",
    "                output_text = load_text(files[\"output\"])\n",
    "                output_obj = parse_output_json(output_text)\n",
    "                if output_obj is None:\n",
    "                    logging.info(f\"[skip] {model} step {step}: output not valid JSON\")\n",
    "                    continue\n",
    "\n",
    "                result = score_one_step(\n",
    "                    scorer=scorer,\n",
    "                    system_prompt=system_prompt,\n",
    "                    global_img_path=files[\"global\"],\n",
    "                    local_img_path=files[\"local\"],\n",
    "                    prompt_text=prompt_text,\n",
    "                    output_json_text=json.dumps(output_obj, ensure_ascii=False),\n",
    "                )\n",
    "                if result is None:\n",
    "                    logging.info(f\"[skip] {model} step {step}: scoring failed\")\n",
    "                    continue\n",
    "\n",
    "                scores = result[\"scores\"]\n",
    "                reasons = result[\"reasons\"]\n",
    "\n",
    "                # 日志简要打印（只显示每个维度的一行理由）\n",
    "                reasons_short = {k: reasons[k] for k in scores.keys()}\n",
    "                logging.info(f\"[score] {model} step {step}: {scores} | reasons: {reasons_short}\")\n",
    "\n",
    "                rec = {\n",
    "                    \"model\": model,\n",
    "                    \"step\": step,\n",
    "                    \"scores\": scores,\n",
    "                    \"reasons\": reasons,\n",
    "                    \"files\": {\n",
    "                        \"global\": os.path.basename(files[\"global\"]),\n",
    "                        \"local\": os.path.basename(files[\"local\"]),\n",
    "                        \"prompt\": os.path.basename(files[\"prompt\"]),\n",
    "                        \"output\": os.path.basename(files[\"output\"]),\n",
    "                    },\n",
    "                }\n",
    "                fout.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "                written += 1\n",
    "\n",
    "        logging.info(f\"[done] {model}: wrote {written} lines -> {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citynav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
